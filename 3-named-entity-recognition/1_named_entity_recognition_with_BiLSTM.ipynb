{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-named-entity-recognition-with-BiLSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLeNQ8n3HtCt7ALNTkrLZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/3-named-entity-recognition/1_named_entity_recognition_with_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie5BQVSb8HSG"
      },
      "source": [
        "## Named Entity Recognition with BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYgOSjly8UPB"
      },
      "source": [
        "One of the fundamental building blocks of NLU is **Named Entity Recognition\n",
        "(NER)**. The names of people, companies, products, and quantities can be tagged in a piece of text with NER, which is very useful in chatbot applications and many other use cases in information retrieval and extraction.\n",
        "\n",
        "Building and training a model capable of doing NER requires several techniques, such as **Conditional Random Fields (CRFs)** and **Bi-directional LSTMs(BiLSTMs)**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsI96aaV8zfx"
      },
      "source": [
        "## Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnBvMUK80sA"
      },
      "source": [
        "Given a sentence or a piece of text, the objective of an NER model is to locate and classify text tokens as named entities in categories such as people's names, organizations and companies, physical locations, quantities, monetary quantities, times, dates, and even protein or DNA sequences. \n",
        "\n",
        "NER should tag the following sentence:\n",
        "\n",
        "```\n",
        "Ashish paid Uber $80 to go to the Twitter offices in San Francisco.\n",
        "```\n",
        "\n",
        "as follows:\n",
        "\n",
        "$$\n",
        "[Ashish]_{PER} \\space paid \\space [Uber]_{ORG} \\space [$80]_{MONEY} \\space to \\space go \\space to \\space the \\space [Twitter]_{ORG} \\space offices \\space in \\space [San Francisco]_{LOC}.\n",
        "$$\n",
        "\n",
        "The most common tags are listed in the table below:\n",
        "\n",
        "| **Type** | Example Tag | Example |\n",
        "|---|---|---|\n",
        "| Person | PER | Gregory went to the castle. |\n",
        "| Organization | ORG | WHO just issued an epidemic advisory.|\n",
        "| Location | LOC | She lives in Seattle. |\n",
        "| Money | MONEY | You owe me twenty dollars. |\n",
        "| Percentage | PERCENT | Stocks have risen 10% today. |\n",
        "| Date | DATE | Let's meet on Wednesday. |\n",
        "| Time | TIME | Is it 5 pm already? |\n",
        "\n",
        "There are different data sets and tagging schemes that can be used to train NER models. Different data sets will have different subsets of the tags.\n",
        "\n",
        "There are a few different ways to build an NER model. If the sentence is considered a sequence, then this task can be modeled as a word-by-word labeling task.\n",
        "\n",
        "Hence, models similar to the models used for Part of Speech (POS) tagging are applicable. Features can be added to a model to improve labeling. The POS of a word and its neighboring words are the most straightforward features to add. Word shape features that model lowercase letters can add a lot of information, principally because a lot of the entity types deal with proper nouns, such as those for people and organizations.\n",
        "\n",
        "Another vital feature involves checking a word in a gazetteer. A gazetteer is like a database of important geographical entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA2OC1OI-ace"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQsSsqzh6qbJ"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGcXyuLAfho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c8e2e13-e037-406a-d376-6903ee90b116"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Model, Input, Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import collections\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxKONS2lAlxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f94f8e9d-bbfd-4e87-a57a-48071ef2bb06"
      },
      "source": [
        "tfds.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.0.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50FcUmjAAnmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3d6d8b-aaaa-4801-e3da-632ccd5b0b65"
      },
      "source": [
        "######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "## Please ignore if not training on GPU       ##\n",
        "## this is important for running CuDNN on GPU ##\n",
        "\n",
        "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "# chck if GPU can be seen by TF\n",
        "tf.config.list_physical_devices('GPU')\n",
        "# only if you want to see how commands are executed, uncomment below\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "###############################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQagKbU9BCF7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget https://gmb.let.rug.nl/releases/gmb-2.2.0.zip\n",
        "\n",
        "# !unzip -o gmb-2.2.0.zip  <= use the -o to expand and overwrite whtout prompting\n",
        "unzip gmb-2.2.0.zip\n",
        "rm -rf gmb-2.2.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDJSmCHCd9e"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-QLg74QCe_C"
      },
      "source": [
        "**The GMB data set**\n",
        "\n",
        "With all the basics in the bag, we are ready to build a model that classifies NERs. For this task, the Groningen Meaning Bank (GMB) data set will be used. This dataset is not considered a gold standard.\n",
        "\n",
        "Also note that since we are going to be working on large data sets, some of the following steps may take some time to execute. In the world of Natural Language Processing (NLP), more training data and training time is key to great results.\n",
        "\n",
        "The data subfolder has a number of subfolders with different files. README supplied with the data set provides details about the various files and their contents. For this example, we will be using only files named en.tags in various subdirectories. These files are tab-separated files with\n",
        "each word of a sentence in a row.\n",
        "\n",
        "Out of lots of fields, we are going to use only the token and the named entity tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJp-SOUyBOII"
      },
      "source": [
        "data_root = './gmb-2.2.0/data/'\n",
        "\n",
        "fnames = []\n",
        "for root, dirs, files in os.walk(data_root):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".tags\"):\n",
        "            fnames.append(os.path.join(root, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaS2rfp9BP-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f5b6fd-4594-4a60-995b-36efaecf7a0b"
      },
      "source": [
        "fnames[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./gmb-2.2.0/data/p05/d0587/en.tags', './gmb-2.2.0/data/p05/d0691/en.tags']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtUMbY9E73cm"
      },
      "source": [
        "A few processing steps need to happen. Each file has a number of sentences, with each words in a row. The entire sentence as a sequence and the corresponding sequence of NER tags need to be fed in as inputs while training the model. As mentioned, the NER tags also need to be simplified to the top-level entities only. Secondly, the NER tags need to be converted to the IOB format. IOB stands for In-Other-Begin. These letters are used as a prefix to the NER tag. The sentence fragment in the table below shows how this scheme works:\n",
        "\n",
        "```\n",
        "Reverend Terry Jones arrived in New    York\n",
        "B-per    I-per I-per O       O  B-geo  I-geo\n",
        "```\n",
        "\n",
        "Note that New York\n",
        "is one location. As soon as New is encountered, it marks the start of the geo NER\n",
        "tag, hence it is assigned B-geo. The next word is York, which is a continuation of\n",
        "the same geographical entity. For any network, classifying the word New as the\n",
        "start of the geographical entity is going to be very challenging. However, a BiLSTM\n",
        "network would be able to see the succeeding words, which helps quite a bit with\n",
        "disambiguation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2HOzLtBQZ0"
      },
      "source": [
        "# First, create a directory to store all the processed files\n",
        "!mkdir ner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_tVvxKl8pQB"
      },
      "source": [
        "We want to process the tags so that we strip the subcategories of the NER tags out. It would also be nice to collect some stats on the types of tags in the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jIxkmY8rTK"
      },
      "source": [
        "ner_tags = collections.Counter()\n",
        "iob_tags = collections.Counter()\n",
        "\n",
        "\n",
        "def strip_ner_subcat(tag):\n",
        "  # NER tags are of form {cat}-{subcat} eg tim-dow. We only want first part\n",
        "  return tag.split(\"-\")[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLoIR2369IDO"
      },
      "source": [
        "The next method takes a sequence of tags and converts them into IOB format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV_q5H9U9KHC"
      },
      "source": [
        "def iob_format(ners):\n",
        "  # converts IO tags into IOB format\n",
        "  # input is a sequence of IO NER tokens\n",
        "  # convert this: O, PERSON, PERSON, O, O, LOCATION, O\n",
        "  # into: O, B-PERSON, I-PERSON, O, O, B-LOCATION, O\n",
        "  iob_tokens = []\n",
        "\n",
        "  for idx, token in enumerate(ners):\n",
        "    if token != \"O\":    # !other\n",
        "      if idx == 0:\n",
        "        token = \"B-\" + token  # start of sentence\n",
        "      elif ners[idx - 1] == token:\n",
        "        token = \"I-\" + token  # continues\n",
        "      else:\n",
        "        token = \"B-\" + token\n",
        "\n",
        "    iob_tokens.append(token)\n",
        "    iob_tags[token] += 1\n",
        "  return iob_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPs5iDTEUNe"
      },
      "source": [
        "Once these two convenience functions are ready, all the tags files need to be read and processed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfw7oiw5EWFX"
      },
      "source": [
        "total_sentences = 0\n",
        "outfiles = []\n",
        "\n",
        "for idx, file in enumerate(fnames):\n",
        "  with open(file, \"rb\") as content:\n",
        "    data = content.read().decode(\"utf-8\").strip()\n",
        "    sentences = data.split(\"\\n\\n\")\n",
        "    print(idx, file, len(sentences))\n",
        "    total_sentences += len(sentences)\n",
        "\n",
        "    with open(\"./ner/\" + str(idx) + \"-\" + os.path.basename(file), \"w\") as outfile:\n",
        "      outfiles.append(\"./ner/\" + str(idx) + \"-\" + os.path.basename(file))\n",
        "      writer = csv.writer(outfile)\n",
        "\n",
        "      for sentence in sentences:\n",
        "        toks = sentence.split(\"\\n\")\n",
        "        words, pos, ner = [], [], []\n",
        "        for tok in toks:\n",
        "          t = tok.split(\"\\t\")\n",
        "          words.append(t[0])\n",
        "          pos.append(t[1])\n",
        "          ner_tags[t[3]] += 1\n",
        "          ner.append(strip_ner_subcat(t[3]))\n",
        "      \n",
        "        writer.writerow([\" \".join(words), \" \".join(iob_format(ner)), \" \".join(pos)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-1e-KqJHUTJ"
      },
      "source": [
        "Files are read and split into two empty newline characters. That is the marker\n",
        "for the end of a sentence in the file. Only the actual words, POS tokens, and NER tokens are used from the file. Once these are collected, a new CSV file is written with three columns: the sentence, a sequence of POS tags, and a sequence of NER tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgYknzQHZWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54941a03-8c96-4cee-de6b-ff83a49c7b28"
      },
      "source": [
        "print(\"total number of sentences:\", total_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of sentences: 62010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKJEJKUdHplj"
      },
      "source": [
        "To confirm the distribution of the NER tags before and after processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTM6QdkuHlLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1163659-7fd9-4e15-b8bd-61ea5d2f8ab1"
      },
      "source": [
        "print(ner_tags)\n",
        "print(iob_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'O': 1146068, 'geo-nam': 58388, 'org-nam': 48034, 'per-nam': 23790, 'gpe-nam': 20680, 'tim-dat': 12786, 'tim-dow': 11404, 'per-tit': 9800, 'per-fam': 8152, 'tim-yoc': 5290, 'tim-moy': 4262, 'per-giv': 2413, 'tim-clo': 891, 'art-nam': 866, 'eve-nam': 602, 'nat-nam': 300, 'tim-nam': 146, 'eve-ord': 107, 'org-leg': 60, 'per-ini': 60, 'per-ord': 38, 'tim-dom': 10, 'art-add': 1, 'per-mid': 1})\n",
            "Counter({'O': 1146068, 'B-geo': 48876, 'B-tim': 26296, 'B-org': 26195, 'I-per': 22270, 'B-per': 21984, 'I-org': 21899, 'B-gpe': 20436, 'I-geo': 9512, 'I-tim': 8493, 'B-art': 503, 'B-eve': 391, 'I-art': 364, 'I-eve': 318, 'I-gpe': 244, 'B-nat': 238, 'I-nat': 62})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8813xDaH6Ya"
      },
      "source": [
        "As is evident, some tags were very infrequent, like tim-dom. It would be next to impossible for a network to learn them. Aggregating up one level helps increase the signal for these tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtJQImWGJdkp"
      },
      "source": [
        "labels, values = zip(*iob_tags.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf_NW68FJli-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "b00a86f4-374f-4974-cb66-35fa2f8dfa10"
      },
      "source": [
        "indexes = np.arange(len(labels))\n",
        "\n",
        "plt.bar(indexes, values)\n",
        "plt.xticks  (indexes, labels, rotation=\"vertical\")\n",
        "plt.margins(0.01)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH8vHVLOH-he"
      },
      "source": [
        "## Normalizing and vectorizing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkdqTCKAH_Y3"
      },
      "source": [
        "For this, pandas and numpy methods will be used. The first step is to load the contents of the processed files into one DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz_Y_ZT_Hu08"
      },
      "source": [
        "# could use `outfiles` param as well\n",
        "files = glob.glob(\"./ner/*.tags\")\n",
        "\n",
        "data_pd = pd.concat([pd.read_csv(f, header=None, names=[\"text\", \"label\", \"pos\"]) for f in files], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUvc1W7PbZdR"
      },
      "source": [
        "This step may take a while given that it is processing 10,000 files. Once the content is loaded, we can check the structure of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lODjENjGbbX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5766af1a-640f-4220-a932-2f8db715615a"
      },
      "source": [
        "data_pd.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62010 entries, 0 to 62009\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    62010 non-null  object\n",
            " 1   label   62010 non-null  object\n",
            " 2   pos     62010 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yin3tYhCbeDI"
      },
      "source": [
        "Both the text and NER tags need to be tokenized and encoded into numbers for\n",
        "use in training. We are going to be using core methods provided by the keras.\n",
        "preprocessing package. \n",
        "\n",
        "First, the tokenizer will be used to tokenize the text. In this example, the text only needs to be tokenized by white spaces, as it has been broken\n",
        "up already:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1A1Ue0Jbzv9"
      },
      "source": [
        "text_token = Tokenizer(filters=\"[\\\\]^\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "pos_token = Tokenizer(filters=\"\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "ner_token = Tokenizer(filters=\"\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "\n",
        "text_token.fit_on_texts(data_pd[\"text\"])\n",
        "pos_token.fit_on_texts(data_pd[\"pos\"])\n",
        "ner_token.fit_on_texts(data_pd[\"label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Nj-JFcdm-I"
      },
      "source": [
        "The default values for the tokenizer are quite reasonable. However, in this particular case, it is important to only tokenize on spaces and not clean the special characters out. Otherwise the data will become mis-formatted.\n",
        "\n",
        "This tokenizer has some useful features. It provides a way to restrict the size of the vocabulary by word counts, TF-IDF, and so on. If the num_words parameter is passed with a numeric value, the tokenizer will limit the number of tokens by word frequencies to that number. The fit_on_texts method takes in all the texts, tokenizes them, and constructs dictionaries with tokens that will be used later to tokenize and encode in one go. \n",
        "\n",
        "A convenience function, get_config(), can be called after the tokenizer has been fit on texts to provide information about the tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KvERC7yeifZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74ee73b-3426-4725-d594-70dc5ac59ccf"
      },
      "source": [
        "ner_config = ner_token.get_config()\n",
        "text_config = text_token.get_config()\n",
        "\n",
        "print(ner_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_words': None, 'filters': '\\t\\n', 'lower': False, 'split': ' ', 'char_level': False, 'oov_token': '<OOV>', 'document_count': 62010, 'word_counts': '{\"B-geo\": 48876, \"O\": 1146068, \"B-per\": 21984, \"I-per\": 22270, \"B-tim\": 26296, \"I-geo\": 9512, \"B-org\": 26195, \"I-org\": 21899, \"B-gpe\": 20436, \"I-tim\": 8493, \"B-eve\": 391, \"I-gpe\": 244, \"B-art\": 503, \"I-art\": 364, \"B-nat\": 238, \"I-eve\": 318, \"I-nat\": 62}', 'word_docs': '{\"B-geo\": 31660, \"I-per\": 13805, \"O\": 61999, \"B-per\": 17499, \"B-tim\": 22345, \"I-geo\": 7738, \"B-gpe\": 16565, \"I-org\": 11011, \"B-org\": 20478, \"I-tim\": 5526, \"B-eve\": 361, \"I-gpe\": 224, \"B-art\": 425, \"I-art\": 207, \"B-nat\": 211, \"I-eve\": 201, \"I-nat\": 50}', 'index_docs': '{\"3\": 31660, \"6\": 13805, \"2\": 61999, \"7\": 17499, \"4\": 22345, \"10\": 7738, \"9\": 16565, \"8\": 11011, \"5\": 20478, \"11\": 5526, \"13\": 361, \"16\": 224, \"12\": 425, \"14\": 207, \"17\": 211, \"15\": 201, \"18\": 50}', 'index_word': '{\"1\": \"<OOV>\", \"2\": \"O\", \"3\": \"B-geo\", \"4\": \"B-tim\", \"5\": \"B-org\", \"6\": \"I-per\", \"7\": \"B-per\", \"8\": \"I-org\", \"9\": \"B-gpe\", \"10\": \"I-geo\", \"11\": \"I-tim\", \"12\": \"B-art\", \"13\": \"B-eve\", \"14\": \"I-art\", \"15\": \"I-eve\", \"16\": \"I-gpe\", \"17\": \"B-nat\", \"18\": \"I-nat\"}', 'word_index': '{\"<OOV>\": 1, \"O\": 2, \"B-geo\": 3, \"B-tim\": 4, \"B-org\": 5, \"I-per\": 6, \"B-per\": 7, \"I-org\": 8, \"B-gpe\": 9, \"I-geo\": 10, \"I-tim\": 11, \"B-art\": 12, \"B-eve\": 13, \"I-art\": 14, \"I-eve\": 15, \"I-gpe\": 16, \"B-nat\": 17, \"I-nat\": 18}'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXUevUAe-J_"
      },
      "source": [
        "The `index_word` dictionary property in the config provides a mapping between\n",
        "IDs and tokens. There is a considerable amount of information in the config. The vocabularies can be obtained from the config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEA7jF-zfEya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c586f65-a40a-43ac-88de-8978d2a47e2b"
      },
      "source": [
        "text_vocab = eval(text_config[\"index_word\"])\n",
        "ner_vocab = eval(ner_config[\"index_word\"])\n",
        "\n",
        "print(\"Unique words in vocab:\", len(text_vocab))\n",
        "print(\"Unique NER tags in vocab:\", len(ner_vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in vocab: 39422\n",
            "Unique NER tags in vocab: 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6cl_eL9fr8g"
      },
      "source": [
        "Tokenizing and encoding text and named entity labels is quite easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ny7-ujrfsn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084e5f9d-3dc4-4457-f54f-773a8904071a"
      },
      "source": [
        "x_token = text_token.texts_to_sequences(data_pd[\"text\"])\n",
        "y_token = ner_token.texts_to_sequences(data_pd[\"label\"])\n",
        "\n",
        "print(text_token.texts_to_sequences([x_token[1]]), data_pd[\"text\"][1])\n",
        "print(ner_token.texts_to_sequences([y_token[1]]), data_pd[\"label\"][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] Trade union chief Amir Peretz won a vote among 100,000 rank-and-file Labor Party members Thursday .\n",
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] O O O B-per I-per O O O O O O O O O B-tim O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIOWhTGTgmQJ"
      },
      "source": [
        "Since sequences are of different sizes, they will all be padded or truncated to a size of 50 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loe707lPgnoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4fac77-d0e8-402c-977a-3b8948ff1d62"
      },
      "source": [
        "max_len = 50\n",
        "\n",
        "x_pad = sequence.pad_sequences(x_token, padding=\"post\", maxlen=max_len)\n",
        "y_pad = sequence.pad_sequences(y_token, padding=\"post\", maxlen=max_len)\n",
        "\n",
        "print(x_pad.shape, y_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62010, 50) (62010, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uHLrgnhpd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe62cf5-dedd-4e38-cae8-99f51f8b4421"
      },
      "source": [
        "text_token.sequences_to_texts([x_pad[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Trade union chief Amir Peretz won a vote among 100,000 rank-and-file Labor Party members Thursday . <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNeORgAPh3zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e95814c-4b6f-4c0b-fa4a-4de7d5369848"
      },
      "source": [
        "ner_token.sequences_to_texts([y_pad[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O O O B-per I-per O O O O O O O O O B-tim O <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7-kb2rEhjAy"
      },
      "source": [
        "There is an additional step that needs to be performed on the labels. Since there are multiple labels, each label token needs to be one-hot encoded like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lx_igSohkS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53c1c06-9a63-47f8-96fd-646b79b5a3ab"
      },
      "source": [
        "num_classes = len(ner_vocab) + 1\n",
        "\n",
        "Y = tf.keras.utils.to_categorical(y_pad, num_classes=num_classes)\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62010, 50, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycIneQV5iRwk"
      },
      "source": [
        "## A BiLSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YZqDivsiTFb"
      },
      "source": [
        "The first model we will try is a BiLSTM model. \n",
        "\n",
        "First, the basic constants need to be set up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ7dLyckfpxm"
      },
      "source": [
        "# Length of the vocabulary\n",
        "vocab_size = len(text_vocab) + 1\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 100\n",
        "\n",
        "# batch size\n",
        "BATCH_SIZE = 90\n",
        "\n",
        "# num of NER classes\n",
        "num_classes = len(ner_vocab) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6iz13iogQAh"
      },
      "source": [
        "Next, a convenience function for instantiating models is defined:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOS5KgE4gQh2"
      },
      "source": [
        "dropout = 0.2\n",
        "\n",
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, classes):\n",
        "  model = tf.keras.Sequential([\n",
        "       Embedding(vocab_size, embedding_dim, mask_zero=True, batch_input_shape=[batch_size, None]),\n",
        "       Bidirectional(LSTM(units=rnn_units, return_sequences=True, dropout=dropout, kernel_initializer=tf.keras.initializers.he_normal())),\n",
        "       TimeDistributed(Dense(rnn_units, activation=\"relu\")),\n",
        "       Dense(num_classes, activation=\"softmax\")                      \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OlN1o1qiFUe"
      },
      "source": [
        "We are going to train our own embeddings. After the embedding layer,\n",
        "there is a BiLSTM layer, followed by a TimeDistributed dense layer. This last\n",
        "layer is different from the sentiment analysis model, where there was only a single unit for binary output. \n",
        "\n",
        "In this problem, for each word in the input sequence, an NER token needs to be predicted. So, the output has as many tokens as the input sequence. Consequently, output tokens correspond 1-to-1 with input tokens and are classified as one of the NER classes. The TimeDistributed layer provides this capability. \n",
        "\n",
        "The other thing to note in this model is the use of regularization. It is important that the model does not overfit the training data. Since LSTMs have high model capacity, using regularization is very important.\n",
        "\n",
        "Now the model can be compiled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co5nYZLmib3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f550c6-539e-42b6-b3b9-4db44f0b2992"
      },
      "source": [
        "model = build_model_bilstm(vocab_size=vocab_size, \n",
        "                           embedding_dim=embedding_dim,\n",
        "                           rnn_units=rnn_units,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           classes=num_classes)\n",
        "model.summary()\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (90, None, 64)            2523072   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (90, None, 200)           132000    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (90, None, 100)           20100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (90, None, 19)            1919      \n",
            "=================================================================\n",
            "Total params: 2,677,091\n",
            "Trainable params: 2,677,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erFYGjsDlKxN"
      },
      "source": [
        "This simplistic model has over 2.6 million parameters!\n",
        "\n",
        ">If you notice, the bulk of the parameters are coming from the size\n",
        "of the vocabulary. The vocabulary has 39,422 words. This increases\n",
        "the model training time and computational capacity required.\n",
        "One way to reduce this is to make the vocabulary size smaller.\n",
        "The easiest way to do this would be to only consider words that\n",
        "have more than a certain frequency of occurrence or to remove\n",
        "words smaller than a certain number of characters. The vocabulary\n",
        "can also be reduced by converting all characters to lower case.\n",
        "However, in NER, case is a very important feature.\n",
        "\n",
        "This model is ready for training. \n",
        "\n",
        "The last thing that is needed is to split the data into train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO_70p1SlXhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6553f2a0-cd68-4ca5-92d2-fa1913433f98"
      },
      "source": [
        "# to enable TensorFlow to process sentences properly\n",
        "X = x_pad\n",
        "\n",
        "# create training and testing splits\n",
        "total_sentences = 62010\n",
        "\n",
        "test_size = round(total_sentences / BATCH_SIZE * 0.2)\n",
        "\n",
        "X_train = X[BATCH_SIZE * test_size:]\n",
        "Y_train = Y[BATCH_SIZE * test_size:]\n",
        "\n",
        "X_test = X[0:BATCH_SIZE * test_size]\n",
        "Y_test = Y[0:BATCH_SIZE * test_size]\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49590, 50) (49590, 50, 19)\n",
            "(12420, 50) (12420, 50, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7triOCztmdS5"
      },
      "source": [
        "Now, the model is ready for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E3IrUtmcou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81951529-9ca4-453a-b95c-952e948fc013"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "551/551 [==============================] - 56s 39ms/step - loss: 0.3613 - accuracy: 0.8513\n",
            "Epoch 2/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0494 - accuracy: 0.9668\n",
            "Epoch 3/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0350 - accuracy: 0.9754\n",
            "Epoch 4/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0289 - accuracy: 0.9789\n",
            "Epoch 5/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0250 - accuracy: 0.9815\n",
            "Epoch 6/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0214 - accuracy: 0.9839\n",
            "Epoch 7/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0187 - accuracy: 0.9862\n",
            "Epoch 8/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0165 - accuracy: 0.9878\n",
            "Epoch 9/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0143 - accuracy: 0.9893\n",
            "Epoch 10/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0125 - accuracy: 0.9906\n",
            "Epoch 11/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 12/15\n",
            "551/551 [==============================] - 22s 39ms/step - loss: 0.0101 - accuracy: 0.9924\n",
            "Epoch 13/15\n",
            "551/551 [==============================] - 21s 39ms/step - loss: 0.0091 - accuracy: 0.9931\n",
            "Epoch 14/15\n",
            "551/551 [==============================] - 21s 39ms/step - loss: 0.0081 - accuracy: 0.9939\n",
            "Epoch 15/15\n",
            "551/551 [==============================] - 21s 38ms/step - loss: 0.0072 - accuracy: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2470109cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhps0DFXmw44"
      },
      "source": [
        "Over 15 epochs of training, the model is doing quite well with over 99% accuracy.\n",
        "\n",
        "Let's see how the model performs on the test set and whether the regularization helped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJTjLHHm0F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70aee72f-b67a-44ea-dae8-b98d0ce86685"
      },
      "source": [
        "model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 8ms/step - loss: 0.0846 - accuracy: 0.9634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08458178490400314, 0.9633784294128418]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R1VTnjQnjft"
      },
      "source": [
        "The model performs well on the test data set, with over 96.5% accuracy. The\n",
        "difference between the train and test accuracies is still there, implying that the model could use some additional regularization. \n",
        "\n",
        "You can play with the dropout variable or add additional dropout layers between the embedding and BiLSTM layers, and between the TimeDistributed layer and the final Dense layer.\n",
        "\n",
        "Here is an example of a sentence fragment tagged by this model:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/sentence-fragment.png?raw=1' width='800'/>\n",
        "\n",
        "This model is not doing poorly at all. It was able to identify the person and time entities in the sentence.\n",
        "\n",
        "As good as this model is, it does not use an important characteristic of named entity tags  a given tag is highly correlated with the tag coming after it. CRFs can take advantage of this information and further improve the accuracy of NER tasks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN1f4wj5egtV"
      },
      "source": [
        "## Conditional random fields (CRFs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiTuOtzwehuX"
      },
      "source": [
        "BiLSTM models look at a sequence of input words and predict the label for the\n",
        "current word. In making this determination, only the information of previous inputs is considered. Previous predictions play no role in making this decision. However, there is information encoded in the sequence of labels that is being discounted.\n",
        "\n",
        "To illustrate this point, consider a subset of NER tags: O, B-Per, I-Per, B-Geo, and I-Geo. This represents two domains of person and geographical entities and an Other category for everything else. Based on the structure of IOB tags, we know that any I- tag must be preceded by a B-I from the same domain. This also implies that an I- tag cannot be preceded by an O tag.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/ner-tag-transitions.png?raw=1' width='800'/>\n",
        "\n",
        "Note that these transition weights can be learned based on the data. Such a learned transition weights matrix could be used during prediction to consider the entire sequence of predicted labels and make updates to the probabilities.\n",
        "\n",
        "Here is an illustrative matrix with indicative transition weights:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/ner-tag-transitions-table.png?raw=1' width='800'/>\n",
        "\n",
        "As per the table above, the weight of the edge connecting I-Org to B-Org has a\n",
        "weight of -1.38, implying that this transition is extremely unlikely to happen.\n",
        "\n",
        "Practically, implementing a CRF has three main steps. The first step is modifying the score generated by the BiLSTM layer and accounting for the transition weights.\n",
        "\n",
        "While decoding, the output sequence is the one that has the maximum score among\n",
        "these possible sequences, calculated conceptually using an style function. The\n",
        "argmax Viterbi algorithm is commonly used to implement a dynamic programming solution for decoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGTX2j15hXI7"
      },
      "source": [
        "## Implementing the custom CRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nkOXPtbp6Wq"
      },
      "source": [
        "### A custom CRF layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awIgFV9VhYs9"
      },
      "source": [
        "Similar to the flow above, there will be an embedding layer and a BiLSTM layer.\n",
        "The output of the BiLSTM needs to be evaluated with the CRF log-likelihood loss. This is the loss that needs to be used to train the model. The\n",
        "first step in implementation is creating a custom layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th3VcYPricv2"
      },
      "source": [
        "class CRFLayer(Layer):\n",
        "  \"\"\"\n",
        "  Computes the log likelihood during training and Performs Viterbi decoding during prediction\n",
        "  \"\"\"\n",
        "  def __init__(self, label_size, mask_id=0, trans_params=None, name=\"crf\", **kwargs):\n",
        "    \"\"\"\n",
        "    The main parameters that are needed are:\n",
        "      1-The number of labels and the transition matrix:This transition parameters matrix is not trainable through\n",
        "      gradient descent. It is calculated as a consequence of computing the loglikelihoods. The transition parameters matrix can also be passed into this\n",
        "      layer if it has been learned in the past.\n",
        "      2-The mask id: Since the sequences are padded, it is important to recover the original sequence lengths for computing transition scores. \n",
        "      By convention, a value of 0 is used for the mask, and that is the default.\n",
        "    \"\"\"\"\n",
        "    super(CRFLayer, self).__init__(name=name, **kwargs)\n",
        "    self.label_size = label_size \n",
        "    self.mask_id = mask_id \n",
        "    self.transition_params = None\n",
        "\n",
        "    if trans_params is None:  # not reloading pretrained params\n",
        "      self.transition_params = tf.Variable(tf.random.uniform(shape=(label_size, label_size)), trainable=False)\n",
        "    else:\n",
        "      self.transition_params = trans_params\n",
        "\n",
        "  def get_seq_lengths(self, matrix):\n",
        "    \"\"\"\n",
        "    The log-likelihood function also requires the actual sequence lengths for each example. \n",
        "    These sequence lengths can be computed from the labels and the mask identifier that was set up in the constructor of this layer.\n",
        "    \"\"\"\n",
        "    # matrix is of shape (batch_size, max_seq_len)\n",
        "    mask = tf.not_equal(matrix, self.mask_id)\n",
        "    seq_lengths = tf.math.reduce_sum(tf.cast(mask, dtype=tf.int32), axis=-1)\n",
        "\n",
        "    return seq_lengths\n",
        "\n",
        "  def call(self, inputs, seq_lengths, training=None):\n",
        "    \"\"\"\n",
        "    The CRF layer is useful only during inference. At inference time, it uses the transition matrix\n",
        "    and logic to correct the sequences' output by the BiLSTM layers before returning them.\n",
        "    \"\"\"\n",
        "    if training is None:\n",
        "      training = K.learning_phase()  # If this variable is not passed, pull from the Keras backend.\n",
        "    \n",
        "    # during training, this layer just returns the logits\n",
        "    if training:\n",
        "      return inputs\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G14UjQGgpjs1"
      },
      "source": [
        "As sequences being passed are masked, this layer needs to know the real sequence\n",
        "lengths during inference time for decoding. A variable is passed for it but is unused at this time. \n",
        "\n",
        "Now that the basic CRF layer is ready, let's build the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUmZfgzopv6i"
      },
      "source": [
        "### A custom CRF model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08YIHOhWpyqn"
      },
      "source": [
        "Since the model builds on a number of preexisting layers in addition to the custom CRF layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXKNq-1kqQ_m"
      },
      "source": [
        "class NerModel(tf.keras.Model):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}