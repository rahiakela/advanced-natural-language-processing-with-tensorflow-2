{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-named-entity-recognition-with-BiLSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDRhmPcMSYxjC+teltn+O+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/3-named-entity-recognition/1_named_entity_recognition_with_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie5BQVSb8HSG"
      },
      "source": [
        "## Named Entity Recognition with BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYgOSjly8UPB"
      },
      "source": [
        "One of the fundamental building blocks of NLU is **Named Entity Recognition\n",
        "(NER)**. The names of people, companies, products, and quantities can be tagged in a piece of text with NER, which is very useful in chatbot applications and many other use cases in information retrieval and extraction.\n",
        "\n",
        "Building and training a model capable of doing NER requires several techniques, such as **Conditional Random Fields (CRFs)** and **Bi-directional LSTMs(BiLSTMs)**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsI96aaV8zfx"
      },
      "source": [
        "## Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnBvMUK80sA"
      },
      "source": [
        "Given a sentence or a piece of text, the objective of an NER model is to locate and classify text tokens as named entities in categories such as people's names, organizations and companies, physical locations, quantities, monetary quantities, times, dates, and even protein or DNA sequences. \n",
        "\n",
        "NER should tag the following sentence:\n",
        "\n",
        "```\n",
        "Ashish paid Uber $80 to go to the Twitter offices in San Francisco.\n",
        "```\n",
        "\n",
        "as follows:\n",
        "\n",
        "$$\n",
        "[Ashish]_{PER} \\space paid \\space [Uber]_{ORG} \\space [$80]_{MONEY} \\space to \\space go \\space to \\space the \\space [Twitter]_{ORG} \\space offices \\space in \\space [San Francisco]_{LOC}.\n",
        "$$\n",
        "\n",
        "The most common tags are listed in the table below:\n",
        "\n",
        "| **Type** | Example Tag | Example |\n",
        "|---|---|---|\n",
        "| Person | PER | Gregory went to the castle. |\n",
        "| Organization | ORG | WHO just issued an epidemic advisory.|\n",
        "| Location | LOC | She lives in Seattle. |\n",
        "| Money | MONEY | You owe me twenty dollars. |\n",
        "| Percentage | PERCENT | Stocks have risen 10% today. |\n",
        "| Date | DATE | Let's meet on Wednesday. |\n",
        "| Time | TIME | Is it 5 pm already? |\n",
        "\n",
        "There are different data sets and tagging schemes that can be used to train NER models. Different data sets will have different subsets of the tags.\n",
        "\n",
        "There are a few different ways to build an NER model. If the sentence is considered a sequence, then this task can be modeled as a word-by-word labeling task.\n",
        "\n",
        "Hence, models similar to the models used for Part of Speech (POS) tagging are applicable. Features can be added to a model to improve labeling. The POS of a word and its neighboring words are the most straightforward features to add. Word shape features that model lowercase letters can add a lot of information, principally because a lot of the entity types deal with proper nouns, such as those for people and organizations.\n",
        "\n",
        "Another vital feature involves checking a word in a gazetteer. A gazetteer is like a database of important geographical entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA2OC1OI-ace"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGcXyuLAfho"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Model, Input, Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import collections\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxKONS2lAlxc"
      },
      "source": [
        "tfds.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50FcUmjAAnmb"
      },
      "source": [
        "######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "## Please ignore if not training on GPU       ##\n",
        "## this is important for running CuDNN on GPU ##\n",
        "\n",
        "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "# chck if GPU can be seen by TF\n",
        "tf.config.list_physical_devices('GPU')\n",
        "# only if you want to see how commands are executed, uncomment below\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "###############################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQagKbU9BCF7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget https://gmb.let.rug.nl/releases/gmb-2.2.0.zip\n",
        "\n",
        "# !unzip -o gmb-2.2.0.zip  <= use the -o to expand and overwrite whtout prompting\n",
        "!unzip gmb-2.2.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDJSmCHCd9e"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-QLg74QCe_C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJp-SOUyBOII"
      },
      "source": [
        "data_root = './gmb-2.2.0/data/'\n",
        "\n",
        "fnames = []\n",
        "for root, dirs, files in os.walk(data_root):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".tags\"):\n",
        "            fnames.append(os.path.join(root, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaS2rfp9BP-Z"
      },
      "source": [
        "fnames[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2HOzLtBQZ0"
      },
      "source": [
        "!mkdir ner"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}