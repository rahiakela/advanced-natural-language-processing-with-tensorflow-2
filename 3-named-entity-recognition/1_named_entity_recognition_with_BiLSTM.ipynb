{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-named-entity-recognition-with-BiLSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPv6BRqcWs241ucwE2mTao+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/3-named-entity-recognition/1_named_entity_recognition_with_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie5BQVSb8HSG"
      },
      "source": [
        "## Named Entity Recognition with BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYgOSjly8UPB"
      },
      "source": [
        "One of the fundamental building blocks of NLU is **Named Entity Recognition\n",
        "(NER)**. The names of people, companies, products, and quantities can be tagged in a piece of text with NER, which is very useful in chatbot applications and many other use cases in information retrieval and extraction.\n",
        "\n",
        "Building and training a model capable of doing NER requires several techniques, such as **Conditional Random Fields (CRFs)** and **Bi-directional LSTMs(BiLSTMs)**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsI96aaV8zfx"
      },
      "source": [
        "## Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnBvMUK80sA"
      },
      "source": [
        "Given a sentence or a piece of text, the objective of an NER model is to locate and classify text tokens as named entities in categories such as people's names, organizations and companies, physical locations, quantities, monetary quantities, times, dates, and even protein or DNA sequences. \n",
        "\n",
        "NER should tag the following sentence:\n",
        "\n",
        "```\n",
        "Ashish paid Uber $80 to go to the Twitter offices in San Francisco.\n",
        "```\n",
        "\n",
        "as follows:\n",
        "\n",
        "$$\n",
        "[Ashish]_{PER} \\space paid \\space [Uber]_{ORG} \\space [$80]_{MONEY} \\space to \\space go \\space to \\space the \\space [Twitter]_{ORG} \\space offices \\space in \\space [San Francisco]_{LOC}.\n",
        "$$\n",
        "\n",
        "The most common tags are listed in the table below:\n",
        "\n",
        "| **Type** | Example Tag | Example |\n",
        "|---|---|---|\n",
        "| Person | PER | Gregory went to the castle. |\n",
        "| Organization | ORG | WHO just issued an epidemic advisory.|\n",
        "| Location | LOC | She lives in Seattle. |\n",
        "| Money | MONEY | You owe me twenty dollars. |\n",
        "| Percentage | PERCENT | Stocks have risen 10% today. |\n",
        "| Date | DATE | Let's meet on Wednesday. |\n",
        "| Time | TIME | Is it 5 pm already? |\n",
        "\n",
        "There are different data sets and tagging schemes that can be used to train NER models. Different data sets will have different subsets of the tags.\n",
        "\n",
        "There are a few different ways to build an NER model. If the sentence is considered a sequence, then this task can be modeled as a word-by-word labeling task.\n",
        "\n",
        "Hence, models similar to the models used for Part of Speech (POS) tagging are applicable. Features can be added to a model to improve labeling. The POS of a word and its neighboring words are the most straightforward features to add. Word shape features that model lowercase letters can add a lot of information, principally because a lot of the entity types deal with proper nouns, such as those for people and organizations.\n",
        "\n",
        "Another vital feature involves checking a word in a gazetteer. A gazetteer is like a database of important geographical entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA2OC1OI-ace"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQsSsqzh6qbJ"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGcXyuLAfho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ea20761-47c7-4ea7-f547-6598e9de597d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Model, Input, Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Dropout\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import collections\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxKONS2lAlxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1707ab9-b8d3-46d0-c92c-834dc7197cd4"
      },
      "source": [
        "tfds.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.0.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50FcUmjAAnmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3d6d8b-aaaa-4801-e3da-632ccd5b0b65"
      },
      "source": [
        "######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "## Please ignore if not training on GPU       ##\n",
        "## this is important for running CuDNN on GPU ##\n",
        "\n",
        "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "# chck if GPU can be seen by TF\n",
        "tf.config.list_physical_devices('GPU')\n",
        "# only if you want to see how commands are executed, uncomment below\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "###############################################"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQagKbU9BCF7"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget https://gmb.let.rug.nl/releases/gmb-2.2.0.zip\n",
        "\n",
        "# !unzip -o gmb-2.2.0.zip  <= use the -o to expand and overwrite whtout prompting\n",
        "unzip gmb-2.2.0.zip\n",
        "rm -rf gmb-2.2.0.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDJSmCHCd9e"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-QLg74QCe_C"
      },
      "source": [
        "**The GMB data set**\n",
        "\n",
        "With all the basics in the bag, we are ready to build a model that classifies NERs. For this task, the Groningen Meaning Bank (GMB) data set will be used. This dataset is not considered a gold standard.\n",
        "\n",
        "Also note that since we are going to be working on large data sets, some of the following steps may take some time to execute. In the world of Natural Language Processing (NLP), more training data and training time is key to great results.\n",
        "\n",
        "The data subfolder has a number of subfolders with different files. README supplied with the data set provides details about the various files and their contents. For this example, we will be using only files named en.tags in various subdirectories. These files are tab-separated files with\n",
        "each word of a sentence in a row.\n",
        "\n",
        "Out of lots of fields, we are going to use only the token and the named entity tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJp-SOUyBOII"
      },
      "source": [
        "data_root = './gmb-2.2.0/data/'\n",
        "\n",
        "fnames = []\n",
        "for root, dirs, files in os.walk(data_root):\n",
        "    for filename in files:\n",
        "        if filename.endswith(\".tags\"):\n",
        "            fnames.append(os.path.join(root, filename))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaS2rfp9BP-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d310ca62-4400-45d7-c69d-6797df70c5d3"
      },
      "source": [
        "fnames[:2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./gmb-2.2.0/data/p00/d0551/en.tags', './gmb-2.2.0/data/p00/d0027/en.tags']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtUMbY9E73cm"
      },
      "source": [
        "A few processing steps need to happen. Each file has a number of sentences, with each words in a row. The entire sentence as a sequence and the corresponding sequence of NER tags need to be fed in as inputs while training the model. As mentioned, the NER tags also need to be simplified to the top-level entities only. Secondly, the NER tags need to be converted to the IOB format. IOB stands for In-Other-Begin. These letters are used as a prefix to the NER tag. The sentence fragment in the table below shows how this scheme works:\n",
        "\n",
        "```\n",
        "Reverend Terry Jones arrived in New    York\n",
        "B-per    I-per I-per O       O  B-geo  I-geo\n",
        "```\n",
        "\n",
        "Note that New York\n",
        "is one location. As soon as New is encountered, it marks the start of the geo NER\n",
        "tag, hence it is assigned B-geo. The next word is York, which is a continuation of\n",
        "the same geographical entity. For any network, classifying the word New as the\n",
        "start of the geographical entity is going to be very challenging. However, a BiLSTM\n",
        "network would be able to see the succeeding words, which helps quite a bit with\n",
        "disambiguation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2HOzLtBQZ0"
      },
      "source": [
        "# First, create a directory to store all the processed files\n",
        "!mkdir ner"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_tVvxKl8pQB"
      },
      "source": [
        "We want to process the tags so that we strip the subcategories of the NER tags out. It would also be nice to collect some stats on the types of tags in the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jIxkmY8rTK"
      },
      "source": [
        "ner_tags = collections.Counter()\n",
        "iob_tags = collections.Counter()\n",
        "\n",
        "\n",
        "def strip_ner_subcat(tag):\n",
        "  # NER tags are of form {cat}-{subcat} eg tim-dow. We only want first part\n",
        "  return tag.split(\"-\")[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLoIR2369IDO"
      },
      "source": [
        "The next method takes a sequence of tags and converts them into IOB format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV_q5H9U9KHC"
      },
      "source": [
        "def iob_format(ners):\n",
        "  # converts IO tags into IOB format\n",
        "  # input is a sequence of IO NER tokens\n",
        "  # convert this: O, PERSON, PERSON, O, O, LOCATION, O\n",
        "  # into: O, B-PERSON, I-PERSON, O, O, B-LOCATION, O\n",
        "  iob_tokens = []\n",
        "\n",
        "  for idx, token in enumerate(ners):\n",
        "    if token != \"O\":    # !other\n",
        "      if idx == 0:\n",
        "        token = \"B-\" + token  # start of sentence\n",
        "      elif ners[idx - 1] == token:\n",
        "        token = \"I-\" + token  # continues\n",
        "      else:\n",
        "        token = \"B-\" + token\n",
        "\n",
        "    iob_tokens.append(token)\n",
        "    iob_tags[token] += 1\n",
        "  return iob_tokens"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPs5iDTEUNe"
      },
      "source": [
        "Once these two convenience functions are ready, all the tags files need to be read and processed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfw7oiw5EWFX"
      },
      "source": [
        "total_sentences = 0\n",
        "outfiles = []\n",
        "\n",
        "for idx, file in enumerate(fnames):\n",
        "  with open(file, \"rb\") as content:\n",
        "    data = content.read().decode(\"utf-8\").strip()\n",
        "    sentences = data.split(\"\\n\\n\")\n",
        "    print(idx, file, len(sentences))\n",
        "    total_sentences += len(sentences)\n",
        "\n",
        "    with open(\"./ner/\" + str(idx) + \"-\" + os.path.basename(file), \"w\") as outfile:\n",
        "      outfiles.append(\"./ner/\" + str(idx) + \"-\" + os.path.basename(file))\n",
        "      writer = csv.writer(outfile)\n",
        "\n",
        "      for sentence in sentences:\n",
        "        toks = sentence.split(\"\\n\")\n",
        "        words, pos, ner = [], [], []\n",
        "        for tok in toks:\n",
        "          t = tok.split(\"\\t\")\n",
        "          words.append(t[0])\n",
        "          pos.append(t[1])\n",
        "          ner_tags[t[3]] += 1\n",
        "          ner.append(strip_ner_subcat(t[3]))\n",
        "      \n",
        "      writer.writerow([\" \".join(words), \" \".join(iob_format(ner)), \" \".join(pos)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-1e-KqJHUTJ"
      },
      "source": [
        "Files are read and split into two empty newline characters. That is the marker\n",
        "for the end of a sentence in the file. Only the actual words, POS tokens, and NER tokens are used from the file. Once these are collected, a new CSV file is written with three columns: the sentence, a sequence of POS tags, and a sequence of NER tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgYknzQHZWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f7a2e2-2cad-463c-e23f-c4b68ee1aa7d"
      },
      "source": [
        "print(\"total number of sentences:\", total_sentences)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of sentences: 62010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKJEJKUdHplj"
      },
      "source": [
        "To confirm the distribution of the NER tags before and after processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTM6QdkuHlLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140627f7-9369-4105-ce5c-6f2e98f033fb"
      },
      "source": [
        "print(ner_tags)\n",
        "print(iob_tags)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'O': 1146068, 'geo-nam': 58388, 'org-nam': 48034, 'per-nam': 23790, 'gpe-nam': 20680, 'tim-dat': 12786, 'tim-dow': 11404, 'per-tit': 9800, 'per-fam': 8152, 'tim-yoc': 5290, 'tim-moy': 4262, 'per-giv': 2413, 'tim-clo': 891, 'art-nam': 866, 'eve-nam': 602, 'nat-nam': 300, 'tim-nam': 146, 'eve-ord': 107, 'per-ini': 60, 'org-leg': 60, 'per-ord': 38, 'tim-dom': 10, 'art-add': 1, 'per-mid': 1})\n",
            "Counter({'O': 177805, 'B-geo': 7364, 'B-org': 4017, 'B-tim': 3734, 'B-per': 3195, 'I-per': 2983, 'B-gpe': 2769, 'I-org': 2575, 'I-geo': 1349, 'I-tim': 1336, 'B-art': 96, 'I-art': 77, 'B-eve': 51, 'I-gpe': 47, 'I-eve': 37, 'B-nat': 32, 'I-nat': 5})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8813xDaH6Ya"
      },
      "source": [
        "As is evident, some tags were very infrequent, like tim-dom. It would be next to impossible for a network to learn them. Aggregating up one level helps increase the signal for these tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtJQImWGJdkp"
      },
      "source": [
        "labels, values = zip(*iob_tags.items())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf_NW68FJli-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "ec2a531d-e8c0-4197-f65d-14b09ed78950"
      },
      "source": [
        "indexes = np.arange(len(labels))\n",
        "\n",
        "plt.bar(indexes, values)\n",
        "plt.xticks  (indexes, labels, rotation=\"vertical\")\n",
        "plt.margins(0.01)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH8vHVLOH-he"
      },
      "source": [
        "## Normalizing and vectorizing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkdqTCKAH_Y3"
      },
      "source": [
        "For this, pandas and numpy methods will be used. The first step is to load the contents of the processed files into one DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz_Y_ZT_Hu08"
      },
      "source": [
        "# could use `outfiles` param as well\n",
        "files = glob.glob(\"./ner/*.tags\")\n",
        "\n",
        "data_pd = pd.concat([pd.read_csv(f, header=None, names=[\"text\", \"label\", \"pos\"]) for f in files], ignore_index=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUvc1W7PbZdR"
      },
      "source": [
        "This step may take a while given that it is processing 10,000 files. Once the content is loaded, we can check the structure of the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lODjENjGbbX5",
        "outputId": "671af246-ae77-4f0a-ae5a-2a330b3932ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_pd.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    10000 non-null  object\n",
            " 1   label   10000 non-null  object\n",
            " 2   pos     10000 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 234.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yin3tYhCbeDI"
      },
      "source": [
        "Both the text and NER tags need to be tokenized and encoded into numbers for\n",
        "use in training. We are going to be using core methods provided by the keras.\n",
        "preprocessing package. \n",
        "\n",
        "First, the tokenizer will be used to tokenize the text. In this example, the text only needs to be tokenized by white spaces, as it has been broken\n",
        "up already:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1A1Ue0Jbzv9"
      },
      "source": [
        "text_token = Tokenizer(filters=\"[\\\\]^\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "pos_token = Tokenizer(filters=\"\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "ner_token = Tokenizer(filters=\"\\t\\n\", lower=False, split=\" \", oov_token=\"<OOV>\")\n",
        "\n",
        "text_token.fit_on_texts(data_pd[\"text\"])\n",
        "pos_token.fit_on_texts(data_pd[\"pos\"])\n",
        "ner_token.fit_on_texts(data_pd[\"label\"])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Nj-JFcdm-I"
      },
      "source": [
        "The default values for the tokenizer are quite reasonable. However, in this particular case, it is important to only tokenize on spaces and not clean the special characters out. Otherwise the data will become mis-formatted.\n",
        "\n",
        "This tokenizer has some useful features. It provides a way to restrict the size of the vocabulary by word counts, TF-IDF, and so on. If the num_words parameter is passed with a numeric value, the tokenizer will limit the number of tokens by word frequencies to that number. The fit_on_texts method takes in all the texts, tokenizes them, and constructs dictionaries with tokens that will be used later to tokenize and encode in one go. \n",
        "\n",
        "A convenience function, get_config(), can be called after the tokenizer has been fit on texts to provide information about the tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KvERC7yeifZ",
        "outputId": "a6484878-27c7-4d3c-dc08-0d4d24d7dc93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ner_config = ner_token.get_config()\n",
        "text_config = text_token.get_config()\n",
        "\n",
        "print(ner_config)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_words': None, 'filters': '\\t\\n', 'lower': False, 'split': ' ', 'char_level': False, 'oov_token': '<OOV>', 'document_count': 10000, 'word_counts': '{\"O\": 177805, \"B-geo\": 7364, \"B-org\": 4017, \"B-per\": 3195, \"I-per\": 2983, \"B-tim\": 3734, \"B-gpe\": 2769, \"I-geo\": 1349, \"I-tim\": 1336, \"I-org\": 2575, \"B-eve\": 51, \"B-art\": 96, \"I-art\": 77, \"I-gpe\": 47, \"I-eve\": 37, \"B-nat\": 32, \"I-nat\": 5}', 'word_docs': '{\"O\": 10000, \"B-geo\": 4730, \"B-org\": 3129, \"B-per\": 2580, \"I-per\": 1993, \"B-tim\": 3180, \"B-gpe\": 2282, \"I-geo\": 1110, \"I-tim\": 900, \"I-org\": 1394, \"B-eve\": 50, \"I-art\": 37, \"B-art\": 71, \"I-gpe\": 41, \"I-eve\": 25, \"B-nat\": 27, \"I-nat\": 5}', 'index_docs': '{\"2\": 10000, \"3\": 4730, \"4\": 3129, \"6\": 2580, \"7\": 1993, \"5\": 3180, \"8\": 2282, \"10\": 1110, \"11\": 900, \"9\": 1394, \"14\": 50, \"13\": 37, \"12\": 71, \"15\": 41, \"16\": 25, \"17\": 27, \"18\": 5}', 'index_word': '{\"1\": \"<OOV>\", \"2\": \"O\", \"3\": \"B-geo\", \"4\": \"B-org\", \"5\": \"B-tim\", \"6\": \"B-per\", \"7\": \"I-per\", \"8\": \"B-gpe\", \"9\": \"I-org\", \"10\": \"I-geo\", \"11\": \"I-tim\", \"12\": \"B-art\", \"13\": \"I-art\", \"14\": \"B-eve\", \"15\": \"I-gpe\", \"16\": \"I-eve\", \"17\": \"B-nat\", \"18\": \"I-nat\"}', 'word_index': '{\"<OOV>\": 1, \"O\": 2, \"B-geo\": 3, \"B-org\": 4, \"B-tim\": 5, \"B-per\": 6, \"I-per\": 7, \"B-gpe\": 8, \"I-org\": 9, \"I-geo\": 10, \"I-tim\": 11, \"B-art\": 12, \"I-art\": 13, \"B-eve\": 14, \"I-gpe\": 15, \"I-eve\": 16, \"B-nat\": 17, \"I-nat\": 18}'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXUevUAe-J_"
      },
      "source": [
        "The `index_word` dictionary property in the config provides a mapping between\n",
        "IDs and tokens. There is a considerable amount of information in the config. The vocabularies can be obtained from the config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEA7jF-zfEya",
        "outputId": "45099d74-e594-48dd-c2f7-536e32375b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_vocab = eval(text_config[\"index_word\"])\n",
        "ner_vocab = eval(ner_config[\"index_word\"])\n",
        "\n",
        "print(\"Unique words in vocab:\", len(text_vocab))\n",
        "print(\"Unique NER tags in vocab:\", len(ner_vocab))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in vocab: 15878\n",
            "Unique NER tags in vocab: 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6cl_eL9fr8g"
      },
      "source": [
        "Tokenizing and encoding text and named entity labels is quite easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ny7-ujrfsn-",
        "outputId": "e26a4a7f-7546-41a1-efe3-a1b9ad54d8a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_token = text_token.texts_to_sequences(data_pd[\"text\"])\n",
        "y_token = ner_token.texts_to_sequences(data_pd[\"label\"])\n",
        "\n",
        "print(text_token.texts_to_sequences([x_token[1]]), data_pd[\"text\"][1])\n",
        "print(ner_token.texts_to_sequences([y_token[1]]), data_pd[\"label\"][1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] Mr. Putin is expected to become Russia 's prime minister .\n",
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] B-per I-per O O O O B-geo O O O O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIOWhTGTgmQJ"
      },
      "source": [
        "Since sequences are of different sizes, they will all be padded or truncated to a size of 50 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loe707lPgnoZ",
        "outputId": "b53af36e-35b0-4f6c-e789-82985170aaf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_len = 50\n",
        "\n",
        "x_pad = sequence.pad_sequences(x_token, padding=\"post\", maxlen=max_len)\n",
        "y_pad = sequence.pad_sequences(y_token, padding=\"post\", maxlen=max_len)\n",
        "\n",
        "print(x_pad.shape, y_pad.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 50) (10000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uHLrgnhpd-",
        "outputId": "e5df637c-dfdd-440a-95d0-f690a92aba74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_token.sequences_to_texts([x_pad[1]])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Mr. Putin is expected to become Russia 's prime minister . <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNeORgAPh3zD",
        "outputId": "35431dfb-7412-47c6-c140-150600c90299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ner_token.sequences_to_texts([y_pad[1]])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-per I-per O O O O B-geo O O O O <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7-kb2rEhjAy"
      },
      "source": [
        "There is an additional step that needs to be performed on the labels. Since there are multiple labels, each label token needs to be one-hot encoded like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lx_igSohkS_",
        "outputId": "e2b1a67a-4d15-4950-d760-3db29dd277f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_classes = len(ner_vocab) + 1\n",
        "\n",
        "Y = tf.keras.utils.to_categorical(y_pad, num_classes=num_classes)\n",
        "Y.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 50, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycIneQV5iRwk"
      },
      "source": [
        "## A BiLSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YZqDivsiTFb"
      },
      "source": [
        "The first model we will try is a BiLSTM model. \n",
        "\n",
        "First, the basic constants need to be set up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ7dLyckfpxm"
      },
      "source": [
        "# Length of the vocabulary\n",
        "vocab_size = len(text_vocab) + 1\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 100\n",
        "\n",
        "# batch size\n",
        "BATCH_SIZE = 90\n",
        "\n",
        "# num of NER classes\n",
        "num_classes = len(ner_vocab) + 1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6iz13iogQAh"
      },
      "source": [
        "Next, a convenience function for instantiating models is defined:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOS5KgE4gQh2"
      },
      "source": [
        "dropout = 0.2\n",
        "\n",
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, classes):\n",
        "  model = tf.keras.Sequential([\n",
        "       Embedding(vocab_size, embedding_dim, mask_zero=True, batch_input_shape=[batch_size, None]),\n",
        "       Bidirectional(LSTM(units=rnn_units, return_sequences=True, dropout=dropout, kernel_initializer=tf.keras.initializers.he_normal())),\n",
        "       TimeDistributed(Dense(rnn_units, activation=\"relu\")),\n",
        "       Dense(num_classes, activation=\"softmax\")                      \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OlN1o1qiFUe"
      },
      "source": [
        "We are going to train our own embeddings. After the embedding layer,\n",
        "there is a BiLSTM layer, followed by a TimeDistributed dense layer. This last\n",
        "layer is different from the sentiment analysis model, where there was only a single unit for binary output. \n",
        "\n",
        "In this problem, for each word in the input sequence, an NER token needs to be predicted. So, the output has as many tokens as the input sequence. Consequently, output tokens correspond 1-to-1 with input tokens and are classified as one of the NER classes. The TimeDistributed layer provides this capability. \n",
        "\n",
        "The other thing to note in this model is the use of regularization. It is important that the model does not overfit the training data. Since LSTMs have high model capacity, using regularization is very important.\n",
        "\n",
        "Now the model can be compiled:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co5nYZLmib3P",
        "outputId": "50ad8004-3915-4dfc-b5af-6f7475f686f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = build_model_bilstm(vocab_size=vocab_size, \n",
        "                           embedding_dim=embedding_dim,\n",
        "                           rnn_units=rnn_units,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           classes=num_classes)\n",
        "model.summary()\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (90, None, 64)            1016256   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (90, None, 200)           132000    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (90, None, 100)           20100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (90, None, 19)            1919      \n",
            "=================================================================\n",
            "Total params: 1,170,275\n",
            "Trainable params: 1,170,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erFYGjsDlKxN"
      },
      "source": [
        "This simplistic model has over 2.6 million parameters!\n",
        "\n",
        ">If you notice, the bulk of the parameters are coming from the size\n",
        "of the vocabulary. The vocabulary has 39,422 words. This increases\n",
        "the model training time and computational capacity required.\n",
        "One way to reduce this is to make the vocabulary size smaller.\n",
        "The easiest way to do this would be to only consider words that\n",
        "have more than a certain frequency of occurrence or to remove\n",
        "words smaller than a certain number of characters. The vocabulary\n",
        "can also be reduced by converting all characters to lower case.\n",
        "However, in NER, case is a very important feature.\n",
        "\n",
        "This model is ready for training. \n",
        "\n",
        "The last thing that is needed is to split the data into train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO_70p1SlXhC",
        "outputId": "4ee916c6-1538-454e-94eb-aef46c9b5f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# to enable TensorFlow to process sentences properly\n",
        "X = x_pad\n",
        "\n",
        "# create training and testing splits\n",
        "total_sentences = 62010\n",
        "\n",
        "test_size = round(total_sentences / BATCH_SIZE * 0.2)\n",
        "\n",
        "X_train = X[BATCH_SIZE * test_size:]\n",
        "Y_train = Y[BATCH_SIZE * test_size:]\n",
        "\n",
        "X_test = X[0:BATCH_SIZE * test_size]\n",
        "Y_test = Y[0:BATCH_SIZE * test_size]\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 50) (0, 50, 19)\n",
            "(10000, 50) (10000, 50, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7triOCztmdS5"
      },
      "source": [
        "Now, the model is ready for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E3IrUtmcou"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhps0DFXmw44"
      },
      "source": [
        "Over 15 epochs of training, the model is doing quite well with over 99% accuracy.\n",
        "\n",
        "Let's see how the model performs on the test set and whether the regularization helped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJTjLHHm0F3"
      },
      "source": [
        "model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R1VTnjQnjft"
      },
      "source": [
        "The model performs well on the test data set, with over 96.5% accuracy. The\n",
        "difference between the train and test accuracies is still there, implying that the model could use some additional regularization. \n",
        "\n",
        "You can play with the dropout variable or add additional dropout layers between the embedding and BiLSTM layers, and between the TimeDistributed layer and the final Dense layer.\n",
        "\n",
        "Here is an example of a sentence fragment tagged by this model:"
      ]
    }
  ]
}