{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-understanding-sentiment-using-glove-based-transfer-learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQf7Gf7sHx/VRNJRu3p289",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/4-transfer-learning/1_understanding_sentiment_using_glove_based_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZQmMt3biyFJ"
      },
      "source": [
        "##Understanding Sentiment using GloVe based transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2oEUmwSjwFy"
      },
      "source": [
        "We have used BiLSTM model to predict the sentiment of IMDb movie reviews. That model learned embeddings of the words from scratch. This model had an accuracy of `83.55%` on the test set, while the SOTA result was closer to `97.4%`. If pre-trained embeddings are used, we expect an increase in model accuracy. \n",
        "\n",
        "Let's try this out and see the impact of transfer learning on this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAlD10-fkC9C"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u34tQYtIkEHv",
        "outputId": "051a43fd-1cd1-4252-c4ca-abe86f973760"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hjVwYZ7kTr1",
        "outputId": "9a069d05-1b94-478e-a9a5-a93aa6c267a2"
      },
      "source": [
        "######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "## Please ignore if not training on GPU       ##\n",
        "## this is important for running CuDNN on GPU ##\n",
        "\n",
        "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "# chck if GPU can be seen by TF\n",
        "tf.config.list_physical_devices('GPU')\n",
        "# only if you want to see how commands are executed\n",
        "#tf.debugging.set_log_device_placement(True)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "###############################################"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LojXqIvwhSE"
      },
      "source": [
        "# Download the GloVe embeddings\n",
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpQRIAuqklY1"
      },
      "source": [
        "##Loading IMDb training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_KDedC2kmPN"
      },
      "source": [
        "TensorFlow Datasets or the tfds package will be used to load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_KrBaGTkqro"
      },
      "source": [
        "imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", split=\"train\", with_info=True, as_supervised=True)\n",
        "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\", as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUvRVMTVm8qc",
        "outputId": "11cf88fb-e582-484f-f94e-ee718142072b"
      },
      "source": [
        "# Check label and example from the dataset\n",
        "for example, label in imdb_train.take(1):\n",
        "  print(example, \"\\n\", label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) \n",
            " tf.Tensor(0, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmIXaviKnVri"
      },
      "source": [
        "## Create Vocab and Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2LLB3egnYBI"
      },
      "source": [
        "After the training and test sets are loaded, the content of the reviews needs to be tokenized and encoded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ_r73znnK50"
      },
      "source": [
        "# Use the default tokenizer settings\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "MAX_TOKENS = 0\n",
        "\n",
        "for example, label in imdb_train:\n",
        "  some_tokens = tokenizer.tokenize(example.numpy())\n",
        "  if MAX_TOKENS < len(some_tokens):\n",
        "    MAX_TOKENS = len(some_tokens)\n",
        "  vocabulary_set.update(some_tokens)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1OrV8IVobgq"
      },
      "source": [
        "We tokenizes the review text and constructs a vocabulary.\n",
        "This vocabulary is used to construct a tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXZQEDpQodFR",
        "outputId": "14a4837e-9b66-47ee-91ef-e7c7a826002f"
      },
      "source": [
        "imdb_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set, lowercase=True, tokenizer=tokenizer)\n",
        "vocab_size = imdb_encoder.vocab_size\n",
        "\n",
        "print(vocab_size, MAX_TOKENS)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93931 2525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykT8a-7Fp_6L"
      },
      "source": [
        "Note that text was converted to lowercase before encoding. Converting to lowercase helps reduce the vocabulary size and may benefit the lookup of corresponding GloVe vectors. Note that capitalization may contain important information, which may help in tasks such as NER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnH7YoWjpt05",
        "outputId": "a9422584-1321-47db-d4aa-4b81de129a86"
      },
      "source": [
        "# Lets verify tokenization and encoding works\n",
        "for example, label in imdb_train.take(1):\n",
        "  print(example, \"\\n\")\n",
        "  encoded = imdb_encoder.encode(example.numpy())\n",
        "  print(encoded, \"\\n\")\n",
        "  print(imdb_encoder.decode(encoded))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) \n",
            "\n",
            "[89793, 90851, 41810, 64523, 42842, 46066, 68939, 53750, 64766, 77911, 56622, 65755, 81772, 46086, 74649, 85007, 75996, 50792, 86109, 92051, 63423, 81211, 89793, 59535, 59974, 64766, 83530, 58701, 88357, 56622, 72891, 63079, 83530, 92051, 65894, 54510, 73951, 88272, 89793, 46066, 68016, 80829, 14341, 89793, 46066, 53613, 41810, 81948, 45799, 40028, 35243, 77544, 87326, 74511, 78243, 62805, 86117, 92855, 89120, 87326, 27078, 66602, 86117, 81259, 83530, 28238, 76444, 66374, 25422, 30191, 59010, 79060, 85797, 55547, 91973, 43674, 66367, 44793, 49356, 46086, 90851, 67886, 81211, 87681, 78243, 59698, 25928, 56622, 87681, 46066, 52058, 90851, 43014, 56722, 83936, 74977, 91156, 50917, 82235, 81051, 52058, 91353, 86109, 14776, 89162, 89793, 79161, 77699, 68016, 89162, 81772, 46086, 68016, 90571, 91128, 50917, 54510, 35098, 40967, 74882, 48263] \n",
            "\n",
            "this was an absolutely terrible movie don t be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movie s ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actor s like christopher walken s good name i could barely sit through it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UneWjRGgtE-u"
      },
      "source": [
        "Now that the tokenizer is ready, the data needs to be tokenized, and sequences\n",
        "padded to a maximum length. Since we are interested in comparing performance\n",
        "with the previosly trained model,we can use the same setting of sampling a maximum of 150 words of the review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JexztWE6rYW5"
      },
      "source": [
        "# transformation functions to be used with the dataset\n",
        "def encode_pad_transform(sample):\n",
        "  encoded = imdb_encoder.encode(sample.numpy())\n",
        "  pad = sequence.pad_sequences([encoded], padding=\"post\", maxlen=150)\n",
        "\n",
        "  return np.array(pad[0], dtype=np.int64)\n",
        "\n",
        "def encode_tf_fn(sample, label):\n",
        "  encoded = tf.py_function(encode_pad_transform, inp=[sample], Tout=(tf.int64))\n",
        "  encoded.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded, label"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-20m9YuJWH"
      },
      "source": [
        "# test the transformation on a small subset\n",
        "subset = imdb_train.take(10)\n",
        "tst = subset.map(encode_tf_fn)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj_T4RM2ufAT",
        "outputId": "725fe92c-2187-4597-c624-3965209dd001"
      },
      "source": [
        "for review, label in tst.take(1):\n",
        "  print(review, label)\n",
        "  print(\"\\n\", imdb_encoder.decode(review))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[89793 90851 41810 64523 42842 46066 68939 53750 64766 77911 56622 65755\n",
            " 81772 46086 74649 85007 75996 50792 86109 92051 63423 81211 89793 59535\n",
            " 59974 64766 83530 58701 88357 56622 72891 63079 83530 92051 65894 54510\n",
            " 73951 88272 89793 46066 68016 80829 14341 89793 46066 53613 41810 81948\n",
            " 45799 40028 35243 77544 87326 74511 78243 62805 86117 92855 89120 87326\n",
            " 27078 66602 86117 81259 83530 28238 76444 66374 25422 30191 59010 79060\n",
            " 85797 55547 91973 43674 66367 44793 49356 46086 90851 67886 81211 87681\n",
            " 78243 59698 25928 56622 87681 46066 52058 90851 43014 56722 83936 74977\n",
            " 91156 50917 82235 81051 52058 91353 86109 14776 89162 89793 79161 77699\n",
            " 68016 89162 81772 46086 68016 90571 91128 50917 54510 35098 40967 74882\n",
            " 48263     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0], shape=(150,), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
            "\n",
            " this was an absolutely terrible movie don t be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movie s ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actor s like christopher walken s good name i could barely sit through it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2f269CWu9JF"
      },
      "source": [
        "Finally, the data is encoded using the convenience functions above like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1MIsBxuyUG"
      },
      "source": [
        "# now tokenize/encode/pad all training and testing data\n",
        "encoded_train = imdb_train.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "encoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsG9s3dcvbcG"
      },
      "source": [
        "At this point, all the training and test data is ready for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zplq4IvcCE"
      },
      "source": [
        "## Loading pre-trained GloVe embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwCPpb_8wTWo"
      },
      "source": [
        "The next step is the foremost step in transfer learning – loading the pre-trained GloVe embeddings and using these as the weights of the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95QVg6XhvV-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}