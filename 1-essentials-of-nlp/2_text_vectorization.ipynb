{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2-text-vectorization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RS6j_Uu1aKr7",
        "Q5NI7lL_aPrR",
        "50W5rWfeOoR3"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/1-essentials-of-nlp/2_text_vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdA7sBdGl2S2"
      },
      "source": [
        "## Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xk0ZWFhsJg7"
      },
      "source": [
        "To understand how to process text, it is important to understand the general\r\n",
        "workflow for NLP.\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/text-processing-workflow.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "The first two steps of the process in the preceding diagram involve collecting labeled data. A supervised model or even a semi-supervised model needs data to operate.\r\n",
        "\r\n",
        "The next step is usually normalizing and featurizing the data. Models have a hard time processing text data as is. There is a lot of hidden structure in a given text that needs to be processed and exposed. These two steps focus on that. \r\n",
        "\r\n",
        "There are a couple of challenges in using the text content of messages. **The first is that text can be of arbitrary lengths.**\r\n",
        "\r\n",
        "Comparing this to image data, we know that each image has a fixed width and height. Even if the corpus of images has a mixture of sizes, images\r\n",
        "can be resized to a common size with minimal loss of information by using a variety of compression mechanisms.\r\n",
        "\r\n",
        "In NLP, this is a bigger problem compared to computer vision. A common approach to handle this is to truncate the text.\r\n",
        "\r\n",
        "**The second issue is that of the representation of words with a numerical quantity or feature.**\r\n",
        "\r\n",
        "In computer vision, the smallest unit is a pixel. Each pixel has a set of\r\n",
        "numerical values indicating color or intensity. \r\n",
        "\r\n",
        "In a text, the smallest unit could be a word. Aggregating the Unicode values of the characters does not convey or embody the meaning of the word.\r\n",
        "\r\n",
        "**A core problem then is to construct a numerical representation of words. Vectorization is the process of converting a word to a vector of numbers that embodies the information contained in the word. Depending on the vectorization technique, this vector may have additional properties that may allow comparison with other words.**\r\n",
        "\r\n",
        "These are the followings text vectorization approach:\r\n",
        "\r\n",
        "- **Count-based vectorization**: The simplest approach for vectorizing is to use counts of words.\r\n",
        "- **TF-IDF based text vectorization**: This is more sophisticated, with its origins in information retrieval.\r\n",
        "- **Word2Vec based text vectorization**: it generate embeddings or word vectors.\r\n",
        "- **BERT based text vectorization**: The newest method in this area.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZPInUZktiyI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy9eSdb1cn4Z",
        "outputId": "50366c86-67e8-4706-9c0c-c1b90f1943a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "%tensorflow_version 2.x     # magic command instructing to use TensorFlow version 2+\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x     # magic command instructing to use TensorFlow version 2+`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOWZnCUXrhlM"
      },
      "source": [
        "# Basic 1-layer neural network model for evaluation\r\n",
        "def make_model(input_dims=3, num_units=12):\r\n",
        "  model = tf.keras.Sequential()\r\n",
        "\r\n",
        "  # Adds a densely-connected layer with 12 units to the model:\r\n",
        "  model.add(tf.keras.layers.Dense(num_units, \r\n",
        "                                  input_dim=input_dims, \r\n",
        "                                  activation='relu'))\r\n",
        "\r\n",
        "  # Add a sigmoid layer with a binary output unit:\r\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  \r\n",
        "  return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ3vRSqLvTu6"
      },
      "source": [
        "## Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr1vzM27oyLD"
      },
      "source": [
        "**The first step of any Machine Learning (ML) project is to obtain a dataset.**\r\n",
        "\r\n",
        "We will be using the SMS Spam Collection dataset made available by University of California, Irvine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSjikP_c0Ba",
        "outputId": "d679752c-c20e-4bf6-c9ae-aa83c9652f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the zip file\n",
        "path_to_zip = tf.keras.utils.get_file(\"smsspamcollection.zip\",\n",
        "                  origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\",\n",
        "                  extract=True)\n",
        "\n",
        "# Unzip the file into a folder\n",
        "!unzip $path_to_zip -d data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "204800/203415 [==============================] - 0s 1us/step\n",
            "Archive:  /root/.keras/datasets/smsspamcollection.zip\n",
            "  inflating: data/SMSSpamCollection  \n",
            "  inflating: data/readme             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytFnxCGFaJ20"
      },
      "source": [
        "# optional step - helps if colab gets disconnected\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbXeir-dm0nr"
      },
      "source": [
        "Reading the data file is trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Kb8AF3wHaKE3",
        "outputId": "882b0eb1-831b-4564-f890-c1c0ba848b78"
      },
      "source": [
        "# Let's see if we read the data correctly\n",
        "# lines = io.open('/content/drive/My Drive/colab-data/SMSSpamCollection').read().strip().split('\\n')\n",
        "lines = io.open('/content/data/SMSSpamCollection').read().strip().split('\\n')\n",
        "lines[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dYG5LFyDm-C-",
        "outputId": "5b562ced-4370-4763-b8d2-8126a43bfcbf"
      },
      "source": [
        "lines[2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCFBMGdWvnNn"
      },
      "source": [
        "### Pre-process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zle10-0pnUjv"
      },
      "source": [
        "The next step is to split each line into two columns – one with the text of the message and the other as the label. While we are separating these labels, we will also convert the labels to numeric values. Since we are interested in predicting spam messages, we can assign a value of 1 to the spam\r\n",
        "messages. A value of 0 will be assigned to legitimate messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhpfi9lWC5We",
        "outputId": "b5106451-e52c-4fb6-f0ce-82a597cd3671"
      },
      "source": [
        "spam_dataset = []\n",
        "spam_count = 0\n",
        "ham_count = 0\n",
        "for line in lines:\n",
        "  label, text = line.split('\\t')\n",
        "  if label.lower().strip() == 'spam':\n",
        "    spam_dataset.append((1, text.strip()))\n",
        "    spam_count += 1\n",
        "  else:\n",
        "    spam_dataset.append(((0, text.strip())))\n",
        "    ham_count += 1\n",
        "\n",
        "spam_dataset[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'),\n",
              " (0, 'Ok lar... Joking wif u oni...'),\n",
              " (1,\n",
              "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"),\n",
              " (0, 'U dun say so early hor... U c already then say...'),\n",
              " (0, \"Nah I don't think he goes to usf, he lives around here though\")]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV1uWIEUoLWQ",
        "outputId": "bcbd7b00-2d39-4ff4-e961-00b19a92db69"
      },
      "source": [
        "print(\"Spam: \", spam_count, \", Ham: \", ham_count)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam:  747 , Ham:  4827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JReDkDrhoSWG"
      },
      "source": [
        "Now the dataset is ready for further processing in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlaM80gFooWR",
        "outputId": "3b18aa37-d702-44b9-e120-7dfcfa7d3dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# To do so, first, we will convert the data into a pandas DataFrame\r\n",
        "df = pd.DataFrame(spam_dataset, columns=['Spam', 'Message'])\r\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Spam                                            Message\n",
              "0     0  Go until jurong point, crazy.. Available only ...\n",
              "1     0                      Ok lar... Joking wif u oni...\n",
              "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3     0  U dun say so early hor... U c already then say...\n",
              "4     0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWcKp2AVoyNY"
      },
      "source": [
        "Now let's split the dataset into training and test sets, with 80% of the records in the training set and the rest in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUBRwsmUoy_m",
        "outputId": "60ee0cbe-b5ef-43ae-e04a-0aaf3d2060d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "train=df.sample(frac=0.8,random_state=42) #random state is a seed value\r\n",
        "test=df.drop(train.index)\r\n",
        "\r\n",
        "train.describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.132765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.339359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam\n",
              "count  4459.000000\n",
              "mean      0.132765\n",
              "std       0.339359\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.000000\n",
              "max       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHpJ94DqkC-"
      },
      "source": [
        "y_train = train[['Spam']]\r\n",
        "y_test = test[['Spam']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50W5rWfeOoR3"
      },
      "source": [
        "## Count-based vectorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGPl4OiyoRzY"
      },
      "source": [
        "The idea behind count-based vectorization is really simple. Each unique word\r\n",
        "appearing in the corpus is assigned a column in the vocabulary. Each document,\r\n",
        "which would correspond to individual messages in the spam example, is assigned\r\n",
        "a row. The counts of the words appearing in that document are entered in\r\n",
        "the relevant cell corresponding to the document and the word. \r\n",
        "\r\n",
        "**With $n$ unique documents containing $m$ unique words, this results in a matrix of $n$ rows by $m$ columns.**\r\n",
        "\r\n",
        "Consider a corpus like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cco-INbyhouu"
      },
      "source": [
        "corpus = [\n",
        "  \"I like fruits. Fruits like bananas\",\n",
        "  \"I love bananas but eat an apple\",\n",
        "  \"An apple a day keeps the doctor away\"\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FoicaJMrMwV"
      },
      "source": [
        "There are three documents in this corpus of text. The scikit-learn (sklearn)\r\n",
        "library provides methods for undertaking count-based vectorization.\r\n",
        "\r\n",
        "The `CountVectorizer` class provides a built-in tokenizer that separates the tokens of two or more characters in length. This class takes a variety of options including a custom tokenizer, a stop word list, the option to convert characters to lowercase prior to tokenization, and a binary mode that converts every positive count to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clVOFDb1ERTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a97f0c-3c01-4519-d61d-31106a7a4c85"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['an',\n",
              " 'apple',\n",
              " 'away',\n",
              " 'bananas',\n",
              " 'but',\n",
              " 'day',\n",
              " 'doctor',\n",
              " 'eat',\n",
              " 'fruits',\n",
              " 'keeps',\n",
              " 'like',\n",
              " 'love',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B3znbFis2qw"
      },
      "source": [
        "The full matrix can be seen as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM7jlBZdFmiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e86138-af30-4ce0-9f83-f1b9d4b9c22a"
      },
      "source": [
        "X.toarray()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0],\n",
              "       [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
              "       [1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHrQlO9itGcl"
      },
      "source": [
        "This process has now converted a sentence such as \"I like fruits. Fruits like bananas\" into a vector `(0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0)`.\r\n",
        "\r\n",
        "**This is an example of context free vectorization. Context-free refers to the fact that the order of the words in the document did not make any difference in the generation of the vector. This is merely counting the instances of the words in a document.**\r\n",
        "\r\n",
        "Consequently, words with multiple meanings may be grouped into one, for example, bank. This may refer to a place near the river or a place to keep money. \r\n",
        "\r\n",
        "**However, it does provide a method to compare documents and derive similarity. The cosine similarity or distance can be computed between two documents, to see which documents are similar to which other documents**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pbT9sH-GwvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64df9835-17cd-4ce9-f3f9-128f4e60deee"
      },
      "source": [
        "cosine_similarity(X.toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.13608276, 0.        ],\n",
              "       [0.13608276, 1.        , 0.3086067 ],\n",
              "       [0.        , 0.3086067 , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q61lNJt0t_6v"
      },
      "source": [
        "This shows that the first sentence and the second sentence have a `0.136` similarity score (on a scale of 0 to 1). The first and third sentence have nothing in common. The second and third sentence have a similarity score of `0.308` – the highest in this set.\r\n",
        "\r\n",
        "**Another use case of this technique is to check the similarity of the documents\r\n",
        "with given keywords.**\r\n",
        "\r\n",
        "Let's say that the query is apple and bananas. This first step is\r\n",
        "to compute the vector of this query, and then compute the cosine similarity scores against the documents in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe6qPCQ4Gxb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2e94db-8c8a-4067-ed21-0a117127c5fa"
      },
      "source": [
        "query = vectorizer.transform([\"apple and bananas\"])\n",
        "\n",
        "cosine_similarity(X, query)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23570226],\n",
              "       [0.57735027],\n",
              "       [0.26726124]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2A93J9gusmf"
      },
      "source": [
        "This shows that this query matches the second sentence in the corpus the best. The third sentence would rank second, and the first sentence would rank lowest.\r\n",
        "\r\n",
        "In a few lines, a basic search engine has been implemented, along with logic to serve queries!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w2zVnOnER_3"
      },
      "source": [
        "## TF-IDF Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec-hagd6kMX7"
      },
      "source": [
        "In creating a vector representation of the document, only the presence of words was included – it does not factor in the importance of a word. If the corpus of documents being processed is about a set of recipes with fruits, then one may expect words like apples, raspberries, and washing to appear frequently. \r\n",
        "\r\n",
        "**Term Frequency (TF) represents how often a word or token occurs in a given document.**\r\n",
        "\r\n",
        "In a set of documents about fruits and cooking, a word like apple may not be terribly specific to help identify a recipe. However, a word like tuile\r\n",
        "may be uncommon in that context. Therefore, it may help to narrow the search for recipes much faster than a word like raspberry. On a side note, feel free to search the web for raspberry tuile recipes. \r\n",
        "\r\n",
        "**If a word is rare, we want to give it a higher weight, as it may contain more information than a common word. A term can be upweighted\r\n",
        "by the inverse of the number of documents it appears in. Consequently, words that occur in a lot of documents will get a smaller score compared to terms that appear in fewer documents. This is called the Inverse Document Frequency (IDF).**\r\n",
        "\r\n",
        "Mathematically, the score of each term in a document can be computed as follows:\r\n",
        "\r\n",
        "$$ TF - IDF(t, d) = TF(t, d) * IDF(t) $$\r\n",
        "\r\n",
        "Here, t represents the word or term, and d represents a specific document.\r\n",
        "\r\n",
        "**It is common to normalize the TF of a term in a document by the total number of tokens in that document.**\r\n",
        "\r\n",
        "The IDF is defined as follows:\r\n",
        "\r\n",
        "$$ IDF(t) = log\\frac{N}{1 + n_t} $$\r\n",
        "\r\n",
        "Here, $N$ represents the total number of documents in the corpus, and $n_t$ represents the number of documents where the term is present. The addition of 1 in the denominator avoids the divide-by-zero error.\r\n",
        "\r\n",
        "Let's convert the counts from the previous section into their TF-IDF equivalents:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKyNZgATHmhM",
        "outputId": "c2c106ad-c474-4c9b-e156-976e62714875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "tfidf = transformer.fit_transform(X.toarray())\n",
        "\n",
        "pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>apple</th>\n",
              "      <th>away</th>\n",
              "      <th>bananas</th>\n",
              "      <th>but</th>\n",
              "      <th>day</th>\n",
              "      <th>doctor</th>\n",
              "      <th>eat</th>\n",
              "      <th>fruits</th>\n",
              "      <th>keeps</th>\n",
              "      <th>like</th>\n",
              "      <th>love</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230408</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.321267</td>\n",
              "      <td>0.321267</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.321267</td>\n",
              "      <td>0.479709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479709</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.275785</td>\n",
              "      <td>0.275785</td>\n",
              "      <td>0.411797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411797</td>\n",
              "      <td>0.411797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.411797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         an     apple      away  ...      like      love       the\n",
              "0  0.000000  0.000000  0.000000  ...  0.688081  0.000000  0.000000\n",
              "1  0.321267  0.321267  0.000000  ...  0.000000  0.479709  0.000000\n",
              "2  0.275785  0.275785  0.411797  ...  0.000000  0.000000  0.411797\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXjwNTxtoBz8"
      },
      "source": [
        "This should give some intuition on how TF-IDF is computed. Even with three toy\r\n",
        "sentences and a very limited vocabulary, many of the columns in each row are 0.\r\n",
        "\r\n",
        "**This vectorization produces sparse representations.**\r\n",
        "\r\n",
        "\r\n",
        "Now, this can be applied to the problem of detecting spam messages. Thus far, the features for each message have been computed based on some aggregate statistics and added to the pandas DataFrame. Now, the content of the message will be tokenized and converted into a set of columns. The TF-IDF score for each word or token will be computed for each message in the array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rifoynAZvO9H"
      },
      "source": [
        "tfidf = TfidfVectorizer(binary=True)\n",
        "X = tfidf.fit_transform(train['Message']).astype('float32')\n",
        "X_test = tfidf.transform(test['Message']).astype('float32')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDnG2OPHwD7U",
        "outputId": "e7f0335b-14d5-4934-9230-3ab91159fbb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4459, 7741)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXoRuIRqpIaR"
      },
      "source": [
        "The second parameter shows that 7,741 tokens were uniquely identified. These are the columns of features that will be used in the model later.\r\n",
        "\r\n",
        "Note that the vectorizer was created with the binary flag. This implies that even if a token appears multiple times in a message, it is counted as one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862RegYipSH_",
        "outputId": "27a235ab-22fa-4cd4-ecb4-01c99c698b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.toarray()[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ3sMm4ApwlO"
      },
      "source": [
        "### Modeling using TF-IDF features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiO1BqAmpyO9"
      },
      "source": [
        "The next trains the TF-IDF model on the training dataset. Then, it converts the words in the test set according to the TF-IDF scores learned from the training set. \r\n",
        "\r\n",
        "Let's train a model on just these TF-IDF features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGujuysLwKJe",
        "outputId": "a7387e67-933d-4037-b553-a50f94c87bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "_, cols = X.shape\n",
        "model2 = make_model(cols)  # to match tf-idf dimensions\n",
        "\n",
        "lb = LabelEncoder()\n",
        "y = lb.fit_transform(y_train)\n",
        "dummy_y_train = np_utils.to_categorical(y)\n",
        "model2.fit(X.toarray(), y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 4s 2ms/step - loss: 0.4988 - accuracy: 0.8623\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1223 - accuracy: 0.9670\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9946\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9968\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9979\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9987\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9992\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90c05dc890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfYJFcbIq3EY"
      },
      "source": [
        "Whoa – we are able to classify every one correctly! In all honesty, the model is probably overfitting, so some regularization should be applied. The test set gives this result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYe6f8my21Y",
        "outputId": "c37d477e-5f72-4bc5-8550-8a9f9e4ea2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.evaluate(X_test.toarray(), y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.054796118289232254, 0.9847533702850342]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYWzn0MqrD_S"
      },
      "source": [
        "An accuracy rate of 98.39% is by far the best we have gotten in any model so far. Checking the confusion matrix, it is evident that this model is indeed doing very well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtRMpISqrI63",
        "outputId": "d5e12acb-953f-43b2-e466-ccb0d549fdc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_pred = model2.predict_classes(X_test.toarray())\r\n",
        "tf.math.confusion_matrix(tf.constant(y_test.Spam), y_test_pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[958,   2],\n",
              "       [ 15, 140]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Va2geD7tETP"
      },
      "source": [
        "Only 2 regular messages were classified as spam, while only 15 spam messages\r\n",
        "were classified as being not spam. This is indeed a very good model.\r\n",
        "\r\n",
        "This model, without using a lot of pretraining and knowledge of\r\n",
        "language, vocabulary, and grammar, was able to do a very reasonable job with the task at hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptf40YDjh71c",
        "outputId": "e1bf96d7-a1ec-494a-934c-843ac9c3e225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "train.loc[train.Spam == 1].describe() "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>592.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Spam\n",
              "count  592.0\n",
              "mean     1.0\n",
              "std      0.0\n",
              "min      1.0\n",
              "25%      1.0\n",
              "50%      1.0\n",
              "75%      1.0\n",
              "max      1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiMYppLxtXSb"
      },
      "source": [
        "However, this model ignores the relationships between words completely. It treats the words in a document as unordered items in a set. There are better models that vectorize the tokens in a way that preserves some of the relationships between the tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMB-9H3IEwm"
      },
      "source": [
        "# Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXyY5EUkIGAS"
      },
      "source": [
        "# memory limit may be exceeded. Try deleting some objects before running this next section\n",
        "# or copy this section to a different notebook.\n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OtFF5X_IZJ4"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hNrv_O2nPgD"
      },
      "source": [
        "api.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eytG4hu4nPSB"
      },
      "source": [
        "model_w2v = api.load(\"word2vec-google-news-300\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lxhBMeIYrl"
      },
      "source": [
        "model_w2v.most_similar(\"cookies\",topn=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkfcI1niIYQ4"
      },
      "source": [
        "model_w2v.doesnt_match([\"USA\",\"Canada\",\"India\",\"Tokyo\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ0lCjnaImWZ"
      },
      "source": [
        "king = model_w2v['king']\n",
        "man = model_w2v['man']\n",
        "woman = model_w2v['woman']\n",
        "\n",
        "queen = king - man + woman  \n",
        "model_w2v.similar_by_vector(queen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2SSPqujo4K8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}